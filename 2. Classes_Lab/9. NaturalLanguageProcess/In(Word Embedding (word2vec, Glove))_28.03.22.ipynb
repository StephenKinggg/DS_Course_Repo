{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2 smart-open-5.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "#from sklearn.manifold import TSNE\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding='utf8' önemli türkçe kelimeleri tanımlaması için. Daha sonra her bir cümlenin \\n ile ayrıştığını görüyoruz aşağıda olduğu gibi. Bundan dolayı her bir cümleyi split(\"\\n\") il ayırıp bunları yeni bir list_sent object atadım. Herbir cümle içindeki tokenleri almak için aşağıdaki kod kullandım.\n",
    "\n",
    "for sent in list_sent:\n",
    "    corpus.append(sent.split())  \n",
    "    \n",
    "Böylece her bir cümle içindeki tokenleri ayırıp corpus içine dahil ettim.\n",
    "Burada önemli olan unique tokenleri değil de tüm tokenleri alarak corpus içine verdim. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('newspaper.txt', 'r', encoding='utf8')\n",
    "text = text.read()\n",
    "list_sent = text.split('\\n')\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sent in list_sent:\n",
    "    corpus.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iran devlet televizyonu ülkedeki eyaletin sinde yapılan reformcuları protesto amaçlı yürüyüşlere milyonlarca kişinin katıldığını bildirdi \\ngösterilerde fitnecilere ölüm münafıklara ölüm abd ye ölüm ingiltere ye ölüm sloganları atıldı \\ndini lider ali hamaney ve cumhurbaşkanı mahmud ahmedinejad ı destekleyen iranlılar son olaylarda yeğeni öldürülen mir hüseyin musevi başta olmak üzere muhalefet liderlerini kınadılar \\nmusevi ye ölüm ve idam idam sloganları duyuldu \\nmuhalefet liderleri kaçtı mı aşure günü yaşanan çatışmalarda devlet kaynaklarına göre u terörist olmak üzere kişi ölmüştü \\nden fazla kişinin yaralandığı olaylar sırasında en az kişi tutuklanmıştı \\nöte yandan iran haber ajansı irna muhalif liderler mir hüseyin musevi ve mehdi kerrubi nin başkentten kaçarak ülkenin kuzeyine geçtiğini ileri sürdü ancak muhalefet iddiayı yalanladı \\nhamaney in bir dönem korumalığını yapan ve şu anda fransa da saklandığı söylenen bir kişinin muhalefete verdiği bilgilere göre münzevi yaşamı na rağmen '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iran devlet televizyonu ülkedeki eyaletin sinde yapılan reformcuları protesto amaçlı yürüyüşlere milyonlarca kişinin katıldığını bildirdi ',\n",
       " 'gösterilerde fitnecilere ölüm münafıklara ölüm abd ye ölüm ingiltere ye ölüm sloganları atıldı ',\n",
       " 'dini lider ali hamaney ve cumhurbaşkanı mahmud ahmedinejad ı destekleyen iranlılar son olaylarda yeğeni öldürülen mir hüseyin musevi başta olmak üzere muhalefet liderlerini kınadılar ',\n",
       " 'musevi ye ölüm ve idam idam sloganları duyuldu ',\n",
       " 'muhalefet liderleri kaçtı mı aşure günü yaşanan çatışmalarda devlet kaynaklarına göre u terörist olmak üzere kişi ölmüştü ',\n",
       " 'den fazla kişinin yaralandığı olaylar sırasında en az kişi tutuklanmıştı ',\n",
       " 'öte yandan iran haber ajansı irna muhalif liderler mir hüseyin musevi ve mehdi kerrubi nin başkentten kaçarak ülkenin kuzeyine geçtiğini ileri sürdü ancak muhalefet iddiayı yalanladı ',\n",
       " 'hamaney in bir dönem korumalığını yapan ve şu anda fransa da saklandığı söylenen bir kişinin muhalefete verdiği bilgilere göre münzevi yaşamı na rağmen dini liderin havyara karşı korkunç bir iştahı var ',\n",
       " 'baston ve at meraklısı hamaney aynı zamanda değerli mücevherlerle bezenmiş bastonların ve cins atların koleksiyonunu yapıyor ',\n",
       " 'hamaney in antika bastonlarının sayısı ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sent[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıda ise cümle içindeki tokenleri ayırıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iran',\n",
       " 'devlet',\n",
       " 'televizyonu',\n",
       " 'ülkedeki',\n",
       " 'eyaletin',\n",
       " 'sinde',\n",
       " 'yapılan',\n",
       " 'reformcuları',\n",
       " 'protesto',\n",
       " 'amaçlı',\n",
       " 'yürüyüşlere',\n",
       " 'milyonlarca',\n",
       " 'kişinin',\n",
       " 'katıldığını',\n",
       " 'bildirdi']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sent[0].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! önemli:\n",
    "\n",
    "Corpus içinde her bir cümle tokenlerine ayrılmış bir şekilde hazır hale getirdim. sonucu bana list olarak verdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin', 'sinde', 'yapılan', 'reformcuları', 'protesto', 'amaçlı', 'yürüyüşlere', 'milyonlarca', 'kişinin', 'katıldığını', 'bildirdi'], ['gösterilerde', 'fitnecilere', 'ölüm', 'münafıklara', 'ölüm', 'abd', 'ye', 'ölüm', 'ingiltere', 'ye', 'ölüm', 'sloganları', 'atıldı'], ['dini', 'lider', 'ali', 'hamaney', 've', 'cumhurbaşkanı', 'mahmud', 'ahmedinejad', 'ı', 'destekleyen', 'iranlılar', 'son', 'olaylarda', 'yeğeni', 'öldürülen', 'mir', 'hüseyin', 'musevi', 'başta', 'olmak', 'üzere', 'muhalefet', 'liderlerini', 'kınadılar'], ['musevi', 'ye', 'ölüm', 've', 'idam', 'idam', 'sloganları', 'duyuldu'], ['muhalefet', 'liderleri', 'kaçtı', 'mı', 'aşure', 'günü', 'yaşanan', 'çatışmalarda', 'devlet', 'kaynaklarına', 'göre', 'u', 'terörist', 'olmak', 'üzere', 'kişi', 'ölmüştü'], ['den', 'fazla', 'kişinin', 'yaralandığı', 'olaylar', 'sırasında', 'en', 'az', 'kişi', 'tutuklanmıştı'], ['öte', 'yandan', 'iran', 'haber', 'ajansı', 'irna', 'muhalif', 'liderler', 'mir', 'hüseyin', 'musevi', 've', 'mehdi', 'kerrubi', 'nin', 'başkentten', 'kaçarak', 'ülkenin', 'kuzeyine', 'geçtiğini', 'ileri', 'sürdü', 'ancak', 'muhalefet', 'iddiayı', 'yalanladı'], ['hamaney', 'in', 'bir', 'dönem', 'korumalığını', 'yapan', 've', 'şu', 'anda', 'fransa', 'da', 'saklandığı', 'söylenen', 'bir', 'kişinin', 'muhalefete', 'verdiği', 'bilgilere', 'göre', 'münzevi', 'yaşamı', 'na', 'rağmen', 'dini', 'liderin', 'havyara', 'karşı', 'korkunç', 'bir', 'iştahı', 'var'], ['baston', 've', 'at', 'meraklısı', 'hamaney', 'aynı', 'zamanda', 'değerli', 'mücevherlerle', 'bezenmiş', 'bastonların', 've', 'cins', 'atların', 'koleksiyonunu', 'yapıyor'], ['hamaney', 'in', 'antika', 'bastonlarının', 'sayısı']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıda ise modelimi oluşturuyorum. size ile oluşturacağım model kaç featuredan oluşsun onu belirtiyorum. 50-100-300 tercih ediliyor.\n",
    "\n",
    "min_count benim corpusumda 5 ve daha az geçenleri eğitime dahil etme demektir.\n",
    "\n",
    "skip gram yani sg, default 0 dır. küçük data setlerinde SkipGram tercih ediliyor. CBOW ise büyük data setlerinde kullanılıyor.\n",
    "\n",
    "Modelin çalışması 10-15 dk sürüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, vector_size=100, window=5, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hangi tokene ait wordembedding görmek istiyorsam içine yazıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.3797100e-02, -3.5247892e-01, -2.8415871e-01,  2.1536726e-01,\n",
       "        6.3067728e-01,  2.1922204e-03, -2.6547804e-01,  6.8247813e-01,\n",
       "        4.7849774e-02, -1.5260935e-01, -2.2127323e-02, -1.6137505e-01,\n",
       "       -2.1252461e-01,  2.3590709e-01, -3.6241910e-01,  4.2809033e-01,\n",
       "        4.1499197e-01, -3.1516123e-01,  2.1635376e-01, -5.3653795e-01,\n",
       "       -2.0317985e-01,  2.7100328e-01,  7.0293957e-01, -5.8367079e-01,\n",
       "       -9.3069989e-03,  1.5847628e-01, -2.8725776e-01, -9.4086945e-02,\n",
       "       -4.1138309e-01,  5.8923548e-01,  4.9496165e-01,  2.5542548e-01,\n",
       "       -2.3930345e-02, -3.4385550e-01,  2.4472895e-01, -1.6605076e-01,\n",
       "       -3.3896253e-01,  6.3068457e-02, -3.7141830e-02, -4.3959332e-01,\n",
       "        6.5212172e-01, -1.6925102e-01,  4.0508878e-01, -1.9744273e-01,\n",
       "        4.3750355e-01,  9.3994103e-03, -4.6932989e-01, -4.2076070e-02,\n",
       "        9.0753488e-02, -1.0142613e-01, -6.3460983e-02, -1.1460091e-01,\n",
       "        2.1437429e-01, -2.3473930e-01, -1.4596568e-01, -1.9864193e-01,\n",
       "       -5.8325633e-02,  1.7994928e-01, -4.2203295e-01, -6.2753302e-01,\n",
       "       -4.2266969e-02,  2.8056523e-01,  2.6144502e-03,  2.9665044e-01,\n",
       "       -1.9767809e-01,  4.7290862e-02,  9.7214602e-02,  9.1126189e-02,\n",
       "       -3.6532769e-01, -6.8246596e-02, -1.5764660e-01,  5.4696526e-02,\n",
       "        3.8997543e-01, -2.5699857e-01,  3.1756079e-01, -2.9065784e-02,\n",
       "       -4.2506045e-04,  2.3242388e-02, -2.5310421e-01, -1.9386356e-01,\n",
       "        7.3040372e-01, -6.9301784e-01,  9.5577851e-02,  7.5548375e-01,\n",
       "        5.4560792e-01, -3.2314083e-01,  2.1424663e-01,  6.8066502e-01,\n",
       "        6.5648699e-01,  5.0148422e-01,  8.2893658e-01, -8.6449742e-02,\n",
       "        6.3603938e-01,  2.0810910e-01,  6.3292783e-01, -1.3257894e-01,\n",
       "        2.2853762e-01, -5.4240163e-02,  1.9107111e-01,  7.5176381e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['ankara']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesela aşağıdaki kelimeler ile şey çok fazla kullanıldığından dolayı bunlar arasında anlamlı bir ilişki kurmuş."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('birşey', 0.8128613233566284),\n",
       " ('şeyin', 0.7624255418777466),\n",
       " ('şeyimiz', 0.754976749420166),\n",
       " ('şeyler', 0.752974808216095),\n",
       " ('şeyim', 0.7486740350723267),\n",
       " ('şeyi', 0.7404916882514954),\n",
       " ('yapabileceğim', 0.7274945378303528),\n",
       " ('şeyle', 0.7229393720626831),\n",
       " ('haberim', 0.7199336886405945),\n",
       " ('yapmazsak', 0.7166200876235962)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('şey') # şey yerine ikame edilebilecek kelimeleri getirdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('çizgileri', 0.644234836101532),\n",
       " ('halıda', 0.6336213946342468),\n",
       " ('sarı', 0.6314988732337952),\n",
       " ('gömlekli', 0.6314800381660461),\n",
       " ('turuncu', 0.6253319382667542),\n",
       " ('bülten', 0.6250900626182556),\n",
       " ('ışıkta', 0.6090176105499268),\n",
       " ('bültenle', 0.6084602475166321),\n",
       " ('renkli', 0.6055247187614441),\n",
       " ('halı', 0.60127192735672)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('kırmızı')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('evine', 0.799938976764679),\n",
       " ('dükkana', 0.7549629807472229),\n",
       " ('apartmana', 0.7298331260681152),\n",
       " ('arabasına', 0.7284806370735168),\n",
       " ('mağazaya', 0.7193397879600525),\n",
       " ('sinemaya', 0.7068408727645874),\n",
       " ('odasına', 0.7027513980865479),\n",
       " ('köye', 0.7020654678344727),\n",
       " ('ormana', 0.6951404809951782),\n",
       " ('hapishaneye', 0.6941877007484436)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('eve')  # aşağıda ise genellikle ikame kelimeleri bulmuş genellikle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marmara', 0.8948399424552917),\n",
       " ('gemisine', 0.6963356733322144),\n",
       " ('baskınıyla', 0.6654385328292847),\n",
       " ('filo', 0.6453638076782227),\n",
       " ('filosundaki', 0.637879490852356),\n",
       " ('baskınına', 0.6373830437660217),\n",
       " ('saldırısındaki', 0.6250012516975403),\n",
       " ('gemisindeki', 0.6198772192001343),\n",
       " ('gemisinde', 0.6130917072296143),\n",
       " ('baskınının', 0.6084919571876526)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('mavi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bir word embedding modelinin ne kadar iyi eğitildiğini bulmak için most_similar func. kullanabiliriz.\n",
    "\n",
    "aşağıda ise öğrenme ile doktor tokenini verip sonra tedaviyi çıkarınca elimde meslek kalır. Buna öğrenmeyi ilave edince sonuçta eğitim ile ilgili bir sonuç beklerim ancak çok alakasız bir sonuç vermiş.\n",
    "\n",
    "aynı şeyi ankara ve rusya yı vererek de deniyoruz. rusyadan moskovayı çıkarınca ülke kalır ve buna ankarayı ilave edince türkiye yi bulmuşum. burada bunu yakaladığını görüyoruz çünkü gazete haberlerinde çevre ülkelerimizin çok fazla geçtiğini değerlendirebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driscoll', 0.7019277215003967)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['öğrenme', 'doktor'], negative=['tedavi'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('türkiye', 0.7129152417182922)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['ankara', 'rusya'], negative=['moskova'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glove direkt olarak kullanamadığımızdan dolayı önce bunu word2vec dönüştürüp word2vec uyguladığım func. glove dan aldığım wordembedding vektörlerine uygulayacağım.\n",
    "\n",
    "glove.6B.100d.txt kullanabilmek için önce word2vec olarak locale kaydediyorum. Daha sonra bunu kendi localimden geri çağırmak için KeyedVectors kullanıyorum.\n",
    "\n",
    "Bu model 6 milyar token ile eğitilmiş. ve her bir token 100 vektör boyutunda. \n",
    "\n",
    "aşağıda önce glove localime word2vec olarak kaydedebilmek için bir isim belirledim('glove.6B.100d.glove'). glove modeli bu isim ile localime kaydedebilmek için glove2word2vec(glove_model, word2vec) kodunu kullandım.  \n",
    "\n",
    "Daha sonra ise model2 = KeyedVectors.load_word2vec_format(word2vec)  ile localimdeki word2vec çağırıyorum.\n",
    "\n",
    "glove ingilizce olduğundan dolayı türkçe kelimeleri tanımaz. yazarsak hata alırız. ingilizce wikipedia üzerinde eğitilmiş. burada ankara ve izmir çıkması bu sebepten. başka bir türkçe ifade yazsak hata alırız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_12404/3171860902.py:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_model, word2vec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model = 'glove.6B.100d.txt'\n",
    "word2vec = 'glove.6B.100d.glove'\n",
    "glove2word2vec(glove_model, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KeyedVectors.load_word2vec_format(word2vec) # localden çağırıyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0021052, -0.1504   ,  0.44277  , -0.77653  ,  0.049685 ,\n",
       "        0.36162  , -0.64556  ,  0.031965 ,  0.32785  ,  1.0492   ,\n",
       "       -0.40957  , -0.43448  ,  0.86788  ,  0.13176  , -0.33421  ,\n",
       "        0.078688 , -0.44023  , -0.78494  , -0.80508  , -0.053829 ,\n",
       "        0.21349  , -0.1304   ,  0.55552  ,  0.80507  , -0.54116  ,\n",
       "        0.14223  , -0.086403 ,  0.049789 ,  0.16237  ,  0.51762  ,\n",
       "       -0.86124  , -0.35288  ,  0.42465  ,  0.29504  , -0.058929 ,\n",
       "       -0.042059 , -0.28304  ,  0.68163  , -0.38128  , -0.92071  ,\n",
       "        0.15022  , -0.48653  , -0.032471 , -1.0217   , -0.2536   ,\n",
       "        0.32984  ,  0.87331  , -0.25659  ,  0.41713  ,  0.70187  ,\n",
       "        0.26844  , -0.073702 ,  0.44943  ,  0.37148  , -1.1613   ,\n",
       "        0.18607  ,  0.22148  , -0.30284  , -0.30314  ,  0.14694  ,\n",
       "       -0.33141  ,  0.65478  , -0.047409 ,  0.73868  , -0.88869  ,\n",
       "       -0.10738  , -1.3663   , -0.40605  , -0.84452  ,  0.079424 ,\n",
       "       -0.57159  , -0.54494  ,  0.88383  ,  0.89814  , -0.65429  ,\n",
       "        0.60613  ,  0.32272  ,  0.14067  , -0.38329  ,  0.14519  ,\n",
       "       -0.16869  , -0.33883  , -0.49892  ,  0.76527  ,  0.65141  ,\n",
       "        0.08416  , -0.41384  ,  0.22261  ,  0.6159   , -0.39172  ,\n",
       "        1.4556   ,  0.31275  , -0.61297  , -0.63733  , -0.05102  ,\n",
       "        0.83986  , -0.33486  ,  0.68343  ,  0.80719  ,  0.17428  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2['izmir'] # her seferinde aynı sonucu alırız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turkey', 0.7512097358703613),\n",
       " ('istanbul', 0.6787630915641785),\n",
       " ('turkish', 0.6690374612808228),\n",
       " ('damascus', 0.6372509002685547),\n",
       " ('tbilisi', 0.6322181820869446),\n",
       " ('erdogan', 0.6258037686347961),\n",
       " ('moscow', 0.6217040419578552),\n",
       " ('brussels', 0.6181437969207764),\n",
       " ('skopje', 0.6164302229881287),\n",
       " ('cyprus', 0.6064030528068542)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('ankara')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('antalya', 0.7520985007286072),\n",
       " ('aomori', 0.7128758430480957),\n",
       " ('istanbul', 0.6664837598800659),\n",
       " ('i̇zmir', 0.6569024920463562),\n",
       " ('malatya', 0.6558743715286255),\n",
       " ('adana', 0.6543141007423401),\n",
       " ('erzurum', 0.6444922685623169),\n",
       " ('kitakyushu', 0.6359541416168213),\n",
       " ('tabriz', 0.6351203322410583),\n",
       " ('bursa', 0.6344613432884216)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('izmir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 0.8083398938179016),\n",
       " ('school', 0.7545564770698547),\n",
       " ('teaching', 0.7521439790725708),\n",
       " ('taught', 0.741184651851654),\n",
       " ('teachers', 0.7291542291641235),\n",
       " ('graduate', 0.7134961485862732),\n",
       " ('instructor', 0.7077119946479797),\n",
       " ('students', 0.6828974485397339),\n",
       " ('teaches', 0.6552315354347229),\n",
       " ('education', 0.6528989672660828)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('teacher') \n",
    "\n",
    "# corpusta instructor az geçtiğinden dolayı oran düşük kalmış."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BERT models hem wikipedia hem de torontadaki mevcut bir kütüphanedeki 100 milyon kitap ile eğitilmiştir. Eğitilmesi 4 gün sürmüştür.\n",
    "\n",
    "teacher    \n",
    "\n",
    "student    0.9222786\n",
    "school     0.9295052\n",
    "teaching   0.9878557\n",
    "taught     0.94827914\n",
    "teachers   0.96148443\n",
    "graduate   0.9457023\n",
    "instructor 0.84273684\n",
    "students   0.98318183\n",
    "teaches    0.9890878\n",
    "education  0.94292575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('physician', 0.7673240303993225),\n",
       " ('nurse', 0.75215083360672),\n",
       " ('dr.', 0.7175194025039673),\n",
       " ('doctors', 0.7080884575843811),\n",
       " ('patient', 0.7074184417724609),\n",
       " ('medical', 0.6995993256568909),\n",
       " ('surgeon', 0.6905338764190674),\n",
       " ('hospital', 0.690092921257019),\n",
       " ('psychiatrist', 0.658909797668457),\n",
       " ('dentist', 0.6447420716285706)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar('doctor')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BERT models ile alınan sonuçlar.\n",
    "\n",
    "doctor   \n",
    "\n",
    "physician    0.98596996\n",
    "nurse        0.75534743\n",
    "dr.          0.88797665\n",
    "doctors      0.9910818\n",
    "patient      0.98758376\n",
    "medical      0.97713757\n",
    "surgeon      0.95054865\n",
    "hospital     0.82682276\n",
    "psychiatrist 0.91220266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wordembedding modellerinin yaptığı kalıplar üzerinden öğretmek. corpus ne kadar büyükse sonuçlar o kadar iyi olur.\n",
    "mesela aşağıda brother dan man çıkarınca kardeşler kalıyor ve woman ekleyince kız kardeşler oluşuyor. güzel yakalamış."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('daughter', 0.8917793035507202)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman', 'brother'], negative=['man'], topn=1)\n",
    "\n",
    "# mesela brother man çıkar ve woman ilave edince kız kardeş kalıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mother', 0.9024619460105896)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman', 'father'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aunt', 0.8368030190467834)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman', 'uncle'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('turkey', 0.81471186876297)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['ankara', 'germany'], negative=['berlin'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('teacher', 0.7610154151916504)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['teach', 'doctor'], negative=['treat'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7698540687561035)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lover', 0.7032662034034729)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(positive=['love', 'jealous'], negative=['hate'], topn=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
